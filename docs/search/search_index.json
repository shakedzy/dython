{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dython A set of D ata analysis tools in p YTHON 3.x. Dython was designed with analysis usage in mind - meaning ease-of-use, functionality and readability are the core values of this library. Production-grade performance, on the other hand, were not considered. Installation Dython can be installed directly using pip : pip install dython If you wish to install from source: pip install git+https://github.com/shakedzy/dython.git Dependencies: numpy , pandas , seaborn , scipy , matplotlib , sklearn Modules Documentation nominal model_utils sampling Examples Examples of nominal.associations and model_utils.roc_graph are available as part of the package. Descriptions and expected outputs can be seen here . Related blogposts Read more about the dython.nominal tools on The Search for Categorical Correlation Read more about using ROC graphs on Hard ROC: Really Understanding & Properly Using ROC and AUC","title":"Home"},{"location":"#dython","text":"A set of D ata analysis tools in p YTHON 3.x. Dython was designed with analysis usage in mind - meaning ease-of-use, functionality and readability are the core values of this library. Production-grade performance, on the other hand, were not considered.","title":"Dython"},{"location":"#installation","text":"Dython can be installed directly using pip : pip install dython If you wish to install from source: pip install git+https://github.com/shakedzy/dython.git Dependencies: numpy , pandas , seaborn , scipy , matplotlib , sklearn","title":"Installation"},{"location":"#modules-documentation","text":"nominal model_utils sampling","title":"Modules Documentation"},{"location":"#examples","text":"Examples of nominal.associations and model_utils.roc_graph are available as part of the package. Descriptions and expected outputs can be seen here .","title":"Examples"},{"location":"#related-blogposts","text":"Read more about the dython.nominal tools on The Search for Categorical Correlation Read more about using ROC graphs on Hard ROC: Really Understanding & Properly Using ROC and AUC","title":"Related blogposts"},{"location":"404/","text":"Nope. There's nothing here.","title":"Nope."},{"location":"404/#nope","text":"There's nothing here.","title":"Nope."},{"location":"examples/","text":"Examples Examples can be imported and executed from dython.examples . associations_iris_example() Plot an example of an associations heat-map of the Iris dataset features. All features of this dataset are numerical (except for the target). Example code: import pandas as pd from sklearn import datasets from dython.nominal import associations # Load data iris = datasets.load_iris() # Convert int classes to strings to allow associations # method to automatically recognize categorical columns target = ['C{}'.format(i) for i in iris.target] # Prepare data X = pd.DataFrame(data=iris.data, columns=iris.feature_names) y = pd.DataFrame(data=target, columns=['target']) df = pd.concat([X, y], axis=1) # Plot features associations associations(df) Output: associations_mushrooms_example() Plot an example of an associations heat-map of the UCI Mushrooms dataset features. All features of this dataset are categorical. This example will use Theil's U. Example code: import pandas as pd from dython.nominal import associations # Download and load data from UCI df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data') df.columns = ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat'] # Plot features associations associations(df, theil_u=True, figsize=(15, 15)) Output: roc_graph_example() Plot an example ROC graph of an SVM model predictions over the Iris dataset. Based on sklearn examples (as was seen on April 2018): http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html Example code: import numpy as np from sklearn import svm, datasets from sklearn.model_selection import train_test_split from sklearn.preprocessing import label_binarize from sklearn.multiclass import OneVsRestClassifier from dython.model_utils import roc_graph # Load data iris = datasets.load_iris() X = iris.data y = label_binarize(iris.target, classes=[0, 1, 2]) # Add noisy features random_state = np.random.RandomState(4) n_samples, n_features = X.shape X = np.c_[X, random_state.randn(n_samples, 200 * n_features)] # Train a model X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0) classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True, random_state=0)) # Predict y_score = classifier.fit(X_train, y_train).predict_proba(X_test) # Plot ROC graphs roc_graph(y_test, y_score, class_names=iris.target_names) Output: Note that due to the nature of np.random.RandomState which is used in this example, the output graph may vary from one machine to another.","title":"Examples"},{"location":"examples/#examples","text":"Examples can be imported and executed from dython.examples .","title":"Examples"},{"location":"examples/#associations_iris_example","text":"Plot an example of an associations heat-map of the Iris dataset features. All features of this dataset are numerical (except for the target). Example code: import pandas as pd from sklearn import datasets from dython.nominal import associations # Load data iris = datasets.load_iris() # Convert int classes to strings to allow associations # method to automatically recognize categorical columns target = ['C{}'.format(i) for i in iris.target] # Prepare data X = pd.DataFrame(data=iris.data, columns=iris.feature_names) y = pd.DataFrame(data=target, columns=['target']) df = pd.concat([X, y], axis=1) # Plot features associations associations(df) Output:","title":"associations_iris_example()"},{"location":"examples/#associations_mushrooms_example","text":"Plot an example of an associations heat-map of the UCI Mushrooms dataset features. All features of this dataset are categorical. This example will use Theil's U. Example code: import pandas as pd from dython.nominal import associations # Download and load data from UCI df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data') df.columns = ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat'] # Plot features associations associations(df, theil_u=True, figsize=(15, 15)) Output:","title":"associations_mushrooms_example()"},{"location":"examples/#roc_graph_example","text":"Plot an example ROC graph of an SVM model predictions over the Iris dataset. Based on sklearn examples (as was seen on April 2018): http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html Example code: import numpy as np from sklearn import svm, datasets from sklearn.model_selection import train_test_split from sklearn.preprocessing import label_binarize from sklearn.multiclass import OneVsRestClassifier from dython.model_utils import roc_graph # Load data iris = datasets.load_iris() X = iris.data y = label_binarize(iris.target, classes=[0, 1, 2]) # Add noisy features random_state = np.random.RandomState(4) n_samples, n_features = X.shape X = np.c_[X, random_state.randn(n_samples, 200 * n_features)] # Train a model X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0) classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True, random_state=0)) # Predict y_score = classifier.fit(X_train, y_train).predict_proba(X_test) # Plot ROC graphs roc_graph(y_test, y_score, class_names=iris.target_names) Output: Note that due to the nature of np.random.RandomState which is used in this example, the output graph may vary from one machine to another.","title":"roc_graph_example()"},{"location":"model_utils/","text":"model_utils roc_graph(y_true, y_pred, micro=True, macro=True, eoptimal_threshold=True, class_names=None, colors=None, ax=None, figsize=None, xlim=(0.,1.), ylim=(0.,1.02), lw=2, ls='-',ms=10,fmt='.2f') Plot a ROC graph of predictor's results (inclusding AUC scores), where each row of y_true and y_pred represent a single example. If there are 1 or two columns only, the data is treated as a binary classification (see input example below). If there are more then 2 columns, each column is considered a unique class, and a ROC graph and AUC score will be computed for each. A Macro-ROC and Micro-ROC are computed and plotted too by default. Based on scikit-learn examples (as was seen on April 2018): y_true : list / NumPy ndarray The true classes of the predicted data y_pred : list / NumPy ndarray The predicted classes micro : Boolean Default = True Whether to calculate a Micro ROC graph (not applicable for binary cases) macro : Boolean Default = True Whether to calculate a Macro ROC graph (not applicable for binary cases) eoptimal_threshold : Boolean Default = True Whether to calculate and display the estimated-optimal threshold for each ROC graph. The estimated-optimal threshold is the closest computed threshold with (fpr,tpr) values closest to (0,1) class_names : list or string Default = None Names of the different classes. In a multi-class classification, the order must match the order of the classes probabilities in the input data. In a binary classification, can be a string or a list. If a list, only the last element will be used. colors : list of Matplotlib color strings or None Default = None List of colors to be used for the plotted curves. If None , falls back to a predefined default. ax : matplotlib ax Default = None Matplotlib Axis on which the curves will be plotted figsize : (int,int) or None Default = None A Matplotlib figure-size tuple. If None , falls back to Matplotlib's default. Only used if ax=None . xlim : (float, float) Default = (0.,1.) X-axis limits. ylim : (float,float) Default = (0.,1.02) Y-axis limits. lw : int Default = 2 Line-width. ls : string Default = '-' Matplotlib line-style string ms : int Default = 10 Marker-size. fmt : string Default = '.2f' String formatting of displayed AUC and threshold numbers. Returns: A dictionary, one key for each class. Each value is another dictionary, holding AUC and eOpT values. Example: See examples . Binary Classification Input Example: Consider a data-set of two data-points where the true class of the first line is class 0, which was predicted with a probability of 0.6, and the second line's true class is 1, with predicted probability of 0.8. # First option: >> roc_graph(y_true=[0,1], y_pred=[0.6,0.8]) # Second option: >> roc_graph(y_true=[[1,0],[0,1]], y_pred=[[0.6,0.4],[0.2,0.8]]) # Both yield the same result random_forest_feature_importance(forest, features, precision=4) Given a trained sklearn.ensemble.RandomForestClassifier , plot the different features based on their importance according to the classifier, from the most important to the least. forest : sklearn.ensemble.RandomForestClassifier A trained RandomForestClassifier features : list A list of the names of the features the classifier was trained on, ordered by the same order the appeared in the training data precision : int Default = 4 Precision of feature importance.","title":"model_utils"},{"location":"model_utils/#model_utils","text":"","title":"model_utils"},{"location":"model_utils/#roc_graphy_true-y_pred-microtrue-macrotrue-eoptimal_thresholdtrue-class_namesnone-colorsnone-axnone-figsizenone-xlim01-ylim0102-lw2-ls-ms10fmt2f","text":"Plot a ROC graph of predictor's results (inclusding AUC scores), where each row of y_true and y_pred represent a single example. If there are 1 or two columns only, the data is treated as a binary classification (see input example below). If there are more then 2 columns, each column is considered a unique class, and a ROC graph and AUC score will be computed for each. A Macro-ROC and Micro-ROC are computed and plotted too by default. Based on scikit-learn examples (as was seen on April 2018): y_true : list / NumPy ndarray The true classes of the predicted data y_pred : list / NumPy ndarray The predicted classes micro : Boolean Default = True Whether to calculate a Micro ROC graph (not applicable for binary cases) macro : Boolean Default = True Whether to calculate a Macro ROC graph (not applicable for binary cases) eoptimal_threshold : Boolean Default = True Whether to calculate and display the estimated-optimal threshold for each ROC graph. The estimated-optimal threshold is the closest computed threshold with (fpr,tpr) values closest to (0,1) class_names : list or string Default = None Names of the different classes. In a multi-class classification, the order must match the order of the classes probabilities in the input data. In a binary classification, can be a string or a list. If a list, only the last element will be used. colors : list of Matplotlib color strings or None Default = None List of colors to be used for the plotted curves. If None , falls back to a predefined default. ax : matplotlib ax Default = None Matplotlib Axis on which the curves will be plotted figsize : (int,int) or None Default = None A Matplotlib figure-size tuple. If None , falls back to Matplotlib's default. Only used if ax=None . xlim : (float, float) Default = (0.,1.) X-axis limits. ylim : (float,float) Default = (0.,1.02) Y-axis limits. lw : int Default = 2 Line-width. ls : string Default = '-' Matplotlib line-style string ms : int Default = 10 Marker-size. fmt : string Default = '.2f' String formatting of displayed AUC and threshold numbers. Returns: A dictionary, one key for each class. Each value is another dictionary, holding AUC and eOpT values. Example: See examples . Binary Classification Input Example: Consider a data-set of two data-points where the true class of the first line is class 0, which was predicted with a probability of 0.6, and the second line's true class is 1, with predicted probability of 0.8. # First option: >> roc_graph(y_true=[0,1], y_pred=[0.6,0.8]) # Second option: >> roc_graph(y_true=[[1,0],[0,1]], y_pred=[[0.6,0.4],[0.2,0.8]]) # Both yield the same result","title":"roc_graph(y_true, y_pred, micro=True, macro=True, eoptimal_threshold=True, class_names=None, colors=None, ax=None, figsize=None, xlim=(0.,1.), ylim=(0.,1.02), lw=2, ls='-',ms=10,fmt='.2f')"},{"location":"model_utils/#random_forest_feature_importanceforest-features-precision4","text":"Given a trained sklearn.ensemble.RandomForestClassifier , plot the different features based on their importance according to the classifier, from the most important to the least. forest : sklearn.ensemble.RandomForestClassifier A trained RandomForestClassifier features : list A list of the names of the features the classifier was trained on, ordered by the same order the appeared in the training data precision : int Default = 4 Precision of feature importance.","title":"random_forest_feature_importance(forest, features, precision=4)"},{"location":"nominal/","text":"nominal associations(dataset, nominal_columns='auto', mark_columns=False, theil_u=False, plot=True, clustering=False, bias_correction=True, nan_strategy=_REPLACE, nan_replace_value=_DEFAULT_REPLACE_VALUE, ax=None, figsize=None, annot=True, fmt='.2f', cmap=None, sv_color='silver') Calculate the correlation/strength-of-association of features in data-set with both categorical (eda_tools) and continuous features using: * Pearson's R for continuous-continuous cases * Correlation Ratio for categorical-continuous cases * Cramer's V or Theil's U for categorical-categorical cases dataset : NumPy ndarray / Pandas DataFrame The data-set for which the features' correlation is computed nominal_columns : string / list / NumPy ndarray Names of columns of the data-set which hold categorical values. Can also be the string 'all' to state that all columns are categorical, 'auto' (default) to identify nominal columns automatically, or None to state none are categorical mark_columns : Boolean Default: False if True, output's columns' names will have a suffix of '(nom)' or '(con)' based on there type (eda_tools or continuous), as provided by nominal_columns theil_u : Boolean Default: False In the case of categorical-categorical feaures, use Theil's U instead of Cramer's V plot : Boolean Default: True Plot a heat-map of the correlation matrix clustering : Boolean Default: False If True, the computed associations will be sorted into groups by similar correlations bias_correction : Boolean Default = True Use bias correction for Cramer's V from Bergsma and Wicher, Journal of the Korean Statistical Society 42 (2013): 323-328. nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop_samples' to remove samples with missing values, 'drop_features' to remove features (columns) with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace' ax : matplotlib Axe Default = None Matplotlib Axis on which the heat-map will be plotted figsize : (int,int) or None Default = None A Matplotlib figure-size tuple. If None , falls back to Matplotlib's default. Only used if ax=None . annot : Boolean Default = True Plot number annotations on the heat-map fmt : string Default = '.2f' String formatting of annotations cmap : Matplotlib colormap or None Default = None A colormap to be used for the heat-map. If None, falls back to Seaborn's heat-map default sv_color : string Default = 'silver' A Matplotlib color. The color to be used when displaying single-value features over the heat-map Returns: A dictionary with the following keys: corr : A DataFrame of the correlation/strength-of-association between all features ax : A Matplotlib Axe Example: See examples . cluster_correlations(corr_mat, indexes=None) Apply agglomerative clustering in order to sort a correlation matrix. Based on this clustering example . corr_mat : Pandas DataFrame A correlation matrix (as output from associations ) indexes : list / NumPy ndarray / Pandas Series A sequence of cluster indexes for sorting. If not present, a clustering is performed. Returns: a sorted correlation matrix ( pd.DataFrame ) cluster indexes based on the original dataset ( list ) Example: >> assoc = associations( customers, plot=False ) >> correlations = assoc['corr'] >> correlations, _ = cluster_correlations(correlations) conditional_entropy(x, y, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE, log_base=math.e) Calculates the conditional entropy of x given y: S(x|y) . Read more on Wikipedia . x : list / NumPy ndarray / Pandas Series A sequence of measurements y : list / NumPy ndarray / Pandas Series A sequence of measurements nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop' to remove samples with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace'. log_base : float Default: math.e Specifying base for calculating entropy. Returns: float correlation_ratio(categories, measurements, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE) Calculates the Correlation Ratio (sometimes marked by the greek letter Eta) for categorical-continuous association. Answers the question - given a continuous value of a measurement, is it possible to know which category is it associated with? Value is in the range [0,1], where 0 means a category cannot be determined by a continuous measurement, and 1 means a category can be determined with absolute certainty. Read more on Wikipedia . categories : list / NumPy ndarray / Pandas Series A sequence of categorical measurements measurements : list / NumPy ndarray / Pandas Series A sequence of continuous measurements nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop' to remove samples with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace'. Returns: float in the range of [0,1] cramers_v(x, y, bias_correction=True, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE) Calculates Cramer's V statistic for categorical-categorical association. This is a symmetric coefficient: V(x,y) = V(y,x) . Read more on Wikipedia . Original function taken from this answer on StackOverflow. x : list / NumPy ndarray / Pandas Series A sequence of categorical measurements y : list / NumPy ndarray / Pandas Series A sequence of categorical measurements bias_correction : Boolean Default = True Use bias correction from Bergsma and Wicher, Journal of the Korean Statistical Society 42 (2013): 323-328. nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop' to remove samples with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace'. Returns: float in the range of [0,1] identify_nominal_columns(dataset, include=['object', 'category']) Given a dataset, identify categorical columns. This is used internally in associations and numerical_encoding , but can also be used directly. dataset : pd.DataFrame include : list Default: ['object', 'category'] which column types to filter by. Returns: list of categorical columns Example: >> df = pd.DataFrame({'col1': ['a', 'b', 'c', 'a'], 'col2': [3, 4, 2, 1]}) >> identify_nominal_columns(df) ['col1'] numerical_encoding(dataset, nominal_columns='auto', drop_single_label=False, drop_fact_dict=True, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE) Encoding a data-set with mixed data (numerical and categorical) to a numerical-only data-set, using the following logic: categorical with only a single value will be marked as zero (or dropped, if requested) categorical with two values will be replaced with the result of Pandas factorize categorical with more than two values will be replaced with the result of Pandas get_dummies numerical columns will not be modified dataset : NumPy ndarray / Pandas DataFrame The data-set to encode nominal_columns : sequence / string Default: 'auto' Names of columns of the data-set which hold categorical values. Can also be the string 'all' to state that all columns are categorical, 'auto' (default) to identify nominal columns automatically, or None to state none are categorical (nothing happens) drop_single_label : Boolean Default: False If True, nominal columns with a only a single value will be dropped. drop_fact_dict : Boolean Default: True If True, the return value will be the encoded DataFrame alone. If False, it will be a tuple of the DataFrame and the dictionary of the binary factorization (originating from pd.factorize) nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop_samples' to remove samples with missing values, 'drop_features' to remove features (columns) with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace' Returns: pd.DataFrame or (pd.DataFrame, dict) . If drop_fact_dict is True, returns the encoded DataFrame. else, returns a tuple of the encoded DataFrame and dictionary, where each key is a two-value column, and the value is the original labels, as supplied by Pandas factorize . Will be empty if no two-value columns are present in the data-set theils_u(x, y, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE) Calculates Theil's U statistic (Uncertainty coefficient) for categorical-categorical association. This is the uncertainty of x given y: value is on the range of [0,1] - where 0 means y provides no information about x, and 1 means y provides full information about x. This is an asymmetric coefficient: U(x,y) != U(y,x) . Read more on Wikipedia . x : list / NumPy ndarray / Pandas Series A sequence of categorical measurements y : list / NumPy ndarray / Pandas Series A sequence of categorical measurements nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop' to remove samples with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace'. Returns: float in the range of [0,1]","title":"nominal"},{"location":"nominal/#nominal","text":"","title":"nominal"},{"location":"nominal/#associationsdataset-nominal_columnsauto-mark_columnsfalse-theil_ufalse-plottrue-clusteringfalse-bias_correctiontrue-nan_strategy_replace-nan_replace_value_default_replace_value-axnone-figsizenone-annottrue-fmt2f-cmapnone-sv_colorsilver","text":"Calculate the correlation/strength-of-association of features in data-set with both categorical (eda_tools) and continuous features using: * Pearson's R for continuous-continuous cases * Correlation Ratio for categorical-continuous cases * Cramer's V or Theil's U for categorical-categorical cases dataset : NumPy ndarray / Pandas DataFrame The data-set for which the features' correlation is computed nominal_columns : string / list / NumPy ndarray Names of columns of the data-set which hold categorical values. Can also be the string 'all' to state that all columns are categorical, 'auto' (default) to identify nominal columns automatically, or None to state none are categorical mark_columns : Boolean Default: False if True, output's columns' names will have a suffix of '(nom)' or '(con)' based on there type (eda_tools or continuous), as provided by nominal_columns theil_u : Boolean Default: False In the case of categorical-categorical feaures, use Theil's U instead of Cramer's V plot : Boolean Default: True Plot a heat-map of the correlation matrix clustering : Boolean Default: False If True, the computed associations will be sorted into groups by similar correlations bias_correction : Boolean Default = True Use bias correction for Cramer's V from Bergsma and Wicher, Journal of the Korean Statistical Society 42 (2013): 323-328. nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop_samples' to remove samples with missing values, 'drop_features' to remove features (columns) with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace' ax : matplotlib Axe Default = None Matplotlib Axis on which the heat-map will be plotted figsize : (int,int) or None Default = None A Matplotlib figure-size tuple. If None , falls back to Matplotlib's default. Only used if ax=None . annot : Boolean Default = True Plot number annotations on the heat-map fmt : string Default = '.2f' String formatting of annotations cmap : Matplotlib colormap or None Default = None A colormap to be used for the heat-map. If None, falls back to Seaborn's heat-map default sv_color : string Default = 'silver' A Matplotlib color. The color to be used when displaying single-value features over the heat-map Returns: A dictionary with the following keys: corr : A DataFrame of the correlation/strength-of-association between all features ax : A Matplotlib Axe Example: See examples .","title":"associations(dataset, nominal_columns='auto', mark_columns=False, theil_u=False, plot=True, clustering=False, bias_correction=True, nan_strategy=_REPLACE, nan_replace_value=_DEFAULT_REPLACE_VALUE, ax=None, figsize=None, annot=True, fmt='.2f', cmap=None, sv_color='silver')"},{"location":"nominal/#cluster_correlationscorr_mat-indexesnone","text":"Apply agglomerative clustering in order to sort a correlation matrix. Based on this clustering example . corr_mat : Pandas DataFrame A correlation matrix (as output from associations ) indexes : list / NumPy ndarray / Pandas Series A sequence of cluster indexes for sorting. If not present, a clustering is performed. Returns: a sorted correlation matrix ( pd.DataFrame ) cluster indexes based on the original dataset ( list ) Example: >> assoc = associations( customers, plot=False ) >> correlations = assoc['corr'] >> correlations, _ = cluster_correlations(correlations)","title":"cluster_correlations(corr_mat, indexes=None)"},{"location":"nominal/#conditional_entropyx-y-nan_strategyreplace-nan_replace_valuedefault_replace_value-log_basemathe","text":"Calculates the conditional entropy of x given y: S(x|y) . Read more on Wikipedia . x : list / NumPy ndarray / Pandas Series A sequence of measurements y : list / NumPy ndarray / Pandas Series A sequence of measurements nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop' to remove samples with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace'. log_base : float Default: math.e Specifying base for calculating entropy. Returns: float","title":"conditional_entropy(x, y, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE, log_base=math.e)"},{"location":"nominal/#correlation_ratiocategories-measurements-nan_strategyreplace-nan_replace_valuedefault_replace_value","text":"Calculates the Correlation Ratio (sometimes marked by the greek letter Eta) for categorical-continuous association. Answers the question - given a continuous value of a measurement, is it possible to know which category is it associated with? Value is in the range [0,1], where 0 means a category cannot be determined by a continuous measurement, and 1 means a category can be determined with absolute certainty. Read more on Wikipedia . categories : list / NumPy ndarray / Pandas Series A sequence of categorical measurements measurements : list / NumPy ndarray / Pandas Series A sequence of continuous measurements nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop' to remove samples with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace'. Returns: float in the range of [0,1]","title":"correlation_ratio(categories, measurements, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE)"},{"location":"nominal/#cramers_vx-y-bias_correctiontrue-nan_strategyreplace-nan_replace_valuedefault_replace_value","text":"Calculates Cramer's V statistic for categorical-categorical association. This is a symmetric coefficient: V(x,y) = V(y,x) . Read more on Wikipedia . Original function taken from this answer on StackOverflow. x : list / NumPy ndarray / Pandas Series A sequence of categorical measurements y : list / NumPy ndarray / Pandas Series A sequence of categorical measurements bias_correction : Boolean Default = True Use bias correction from Bergsma and Wicher, Journal of the Korean Statistical Society 42 (2013): 323-328. nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop' to remove samples with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace'. Returns: float in the range of [0,1]","title":"cramers_v(x, y, bias_correction=True, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE)"},{"location":"nominal/#identify_nominal_columnsdataset-includeobject-category","text":"Given a dataset, identify categorical columns. This is used internally in associations and numerical_encoding , but can also be used directly. dataset : pd.DataFrame include : list Default: ['object', 'category'] which column types to filter by. Returns: list of categorical columns Example: >> df = pd.DataFrame({'col1': ['a', 'b', 'c', 'a'], 'col2': [3, 4, 2, 1]}) >> identify_nominal_columns(df) ['col1']","title":"identify_nominal_columns(dataset, include=['object', 'category'])"},{"location":"nominal/#numerical_encodingdataset-nominal_columnsauto-drop_single_labelfalse-drop_fact_dicttrue-nan_strategyreplace-nan_replace_valuedefault_replace_value","text":"Encoding a data-set with mixed data (numerical and categorical) to a numerical-only data-set, using the following logic: categorical with only a single value will be marked as zero (or dropped, if requested) categorical with two values will be replaced with the result of Pandas factorize categorical with more than two values will be replaced with the result of Pandas get_dummies numerical columns will not be modified dataset : NumPy ndarray / Pandas DataFrame The data-set to encode nominal_columns : sequence / string Default: 'auto' Names of columns of the data-set which hold categorical values. Can also be the string 'all' to state that all columns are categorical, 'auto' (default) to identify nominal columns automatically, or None to state none are categorical (nothing happens) drop_single_label : Boolean Default: False If True, nominal columns with a only a single value will be dropped. drop_fact_dict : Boolean Default: True If True, the return value will be the encoded DataFrame alone. If False, it will be a tuple of the DataFrame and the dictionary of the binary factorization (originating from pd.factorize) nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop_samples' to remove samples with missing values, 'drop_features' to remove features (columns) with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace' Returns: pd.DataFrame or (pd.DataFrame, dict) . If drop_fact_dict is True, returns the encoded DataFrame. else, returns a tuple of the encoded DataFrame and dictionary, where each key is a two-value column, and the value is the original labels, as supplied by Pandas factorize . Will be empty if no two-value columns are present in the data-set","title":"numerical_encoding(dataset, nominal_columns='auto', drop_single_label=False, drop_fact_dict=True, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE)"},{"location":"nominal/#theils_ux-y-nan_strategyreplace-nan_replace_valuedefault_replace_value","text":"Calculates Theil's U statistic (Uncertainty coefficient) for categorical-categorical association. This is the uncertainty of x given y: value is on the range of [0,1] - where 0 means y provides no information about x, and 1 means y provides full information about x. This is an asymmetric coefficient: U(x,y) != U(y,x) . Read more on Wikipedia . x : list / NumPy ndarray / Pandas Series A sequence of categorical measurements y : list / NumPy ndarray / Pandas Series A sequence of categorical measurements nan_strategy : string Default: 'replace' How to handle missing values: can be either 'drop' to remove samples with missing values, or 'replace' to replace all missing values with the nan_replace_value. Missing values are None and np.nan. nan_replace_value : any Default: 0.0 The value used to replace missing values with. Only applicable when nan_strategy is set to 'replace'. Returns: float in the range of [0,1]","title":"theils_u(x, y, nan_strategy=REPLACE, nan_replace_value=DEFAULT_REPLACE_VALUE)"},{"location":"sampling/","text":"sampling boltzmann_sampling(numbers, k=1, with_replacement=False) Return k numbers from a boltzmann-sampling over the supplied numbers numbers : List or np.ndarray numbers to sample k : int Default: 1 How many numbers to sample. Choosing k=None will yield a single number with_replacement : Boolean Default: False Allow replacement or not Returns: list , np.ndarray or a single number (depending on the input) weighted_sampling(numbers, k=1, with_replacement=False) Return k numbers from a weighted-sampling over the supplied numbers numbers : List or np.ndarray numbers to sample k : int Default: 1 How many numbers to sample. Choosing k=None will yield a single number with_replacement : Boolean Default: False Allow replacement or not Returns: list , np.ndarray or a single number (depending on the input)","title":"sampling"},{"location":"sampling/#sampling","text":"","title":"sampling"},{"location":"sampling/#boltzmann_samplingnumbers-k1-with_replacementfalse","text":"Return k numbers from a boltzmann-sampling over the supplied numbers numbers : List or np.ndarray numbers to sample k : int Default: 1 How many numbers to sample. Choosing k=None will yield a single number with_replacement : Boolean Default: False Allow replacement or not Returns: list , np.ndarray or a single number (depending on the input)","title":"boltzmann_sampling(numbers, k=1, with_replacement=False)"},{"location":"sampling/#weighted_samplingnumbers-k1-with_replacementfalse","text":"Return k numbers from a weighted-sampling over the supplied numbers numbers : List or np.ndarray numbers to sample k : int Default: 1 How many numbers to sample. Choosing k=None will yield a single number with_replacement : Boolean Default: False Allow replacement or not Returns: list , np.ndarray or a single number (depending on the input)","title":"weighted_sampling(numbers, k=1, with_replacement=False)"}]}